# 实验报告

#### 221900073 孙佳琪



## lab1

### 安装Docker

安装成功的截图如下所示：

![截图 2025-02-21 14-39-00](C:\Users\sjq\Downloads\截图 2025-02-21 1\截图 2025-02-21 14-39-00.png)



### 配置VSCode使用Docker

![截图 2025-02-21 15-01-36](C:\Users\sjq\Downloads\截图 2025-02-21 1\截图 2025-02-21 15-01-36.png)

![截图 2025-02-21 14-49-13](C:\Users\sjq\Downloads\截图 2025-02-21 1\截图 2025-02-21 14-49-13.png)

根据该截图所示，已经进入到Docker容器内部，相关插件也已经下载完毕。



![截图 2025-02-21 15-36-20](C:\Users\sjq\Downloads\截图 2025-02-21 1\截图 2025-02-21 15-36-20.png)

版本号以及是否能运行pytorch如上所示。


### pytorch练习

![截图 2025-02-21 16-31-42](C:\Users\sjq\Desktop\college\深度学习及其应用\lab1\截图 2025-02-21 16-31-42.png)

按序使用所给代码中的函数，计算损失、清空梯度、反向传播、优化器更新参数，最后得到的运行结果如图所示。



通过本次实验，我对张量（tensor）有了一些基本的认识，也学会了如何创建、操作和转换张量，例如使用`torch.arange`生成序列、使用`reshape`改变张量的形状等。这些操作也会是构建和训练模型的基础。模仿第四件的训练过程，使用文档中介绍的API最终补全了训练过程。



## lab2



## lab2_p1

#### 思考题

如果不打乱训练集，在训练过程中可能会遇到以下问题：

​	**过拟合**：模型可能会过度拟合训练数据的顺序，导致在测试数据上的表现不佳。

​	**训练不稳定**：如果训练数据有某种顺序（例如，所有同一类别的样本都集中在一起），模型可能会在训练过程中偏向于某些类别，导致训练过程不稳定。

​	**收敛速度慢**：打乱数据可以帮助模型更快地收敛，因为每次迭代都能看到不同的数据分布。如果不打乱数据，模型可能需要更多的迭代次数才能收敛。



#### 准确率函数

![image-20250302113205373](C:\Users\sjq\Desktop\college\深度学习及其应用\lab1\image-20250302113205373.png)

函数的实现如图所示，`y_hat` 是模型对每个样本的预测结果，通常是一个概率分布。使用 `argmax(dim=1)` 函数从 `y_hat` 中提取每个样本的预测类别。`dim=1` 表示在类别维度上取最大值对应的索引。将预测类别 `pred` 与真实标签 `y` 进行比较，得到一个布尔张量。将当前批次的样本数量 `y.shape[0]` 累加到 `n` 中，最终准确率通过 `acc_sum / n` 计算，即正确预测的样本数量除以总样本数量。

在多层感知机的简单实现部分中，准确率函数也是这样子实现。



#### 训练模型

![image-20250302113556213](C:\Users\sjq\Desktop\college\深度学习及其应用\lab1\image-20250302113556213.png)

训练模型的代码以及运行结果如图所示。

需要不全的是损失值和训练准确率的部分，损失值累加即可得到`train_l_sum`的值，`train_acc_sum`则是需要通过累加预测值等于实际值的情况。



![image-20250302114035116](C:\Users\sjq\Desktop\college\深度学习及其应用\lab1\image-20250302114035116.png)

多层感知机部分的训练模型代码以及运行结果如图所示。

按照注释实现相关步骤即可实现。





## lab2_p2



#### 激活函数的实现与可视化

![image-20250302140806344](C:\Users\sjq\Desktop\college\深度学习及其应用\lab1\image-20250302140806344.png)

运行结果在.ipy2nb文件中有显示。

思考题：

​	神经网络的核心优势在于其能够学习和表示复杂的非线性关系。非线性激活函数（如ReLU、Sigmoid、Tanh等）能够将输入数据映射到非线性空间，使得神经网络能够拟合复杂的函数。如果没有非线性激活函数，无论神经网络有多少层，它都只能表示线性关系。许多实际问题（如图像分类、语音识别等）都是非线性的，使用线性激活函数将无法有效解决这些问题。



#### 梯度消失问题实验

![image-20250302141121726](C:\Users\sjq\Desktop\college\深度学习及其应用\lab1\image-20250302141121726.png)



前向传播函数的实现如图所示。

运行结果在.ipy2nb文件中有显示。

思考题：

​	Sigmoid函数的导数范围是(0, 0.25)。当输入值较大或较小时，梯度接近于0，容易导致梯度消失问题。Tanh函数的导数范围是(0, 1)。虽然比Sigmoid稍好，但在输入值较大或较小时，梯度仍然接近于0，可能导致梯度消失。ReLU函数的导数在正区间内为1，在负区间内为0。ReLU在正区间内不会出现梯度消失问题，但在负区间内可能导致神经元“死亡”。

​	梯度消失问题是指在反向传播过程中，梯度逐渐变小，导致网络参数更新缓慢甚至停止更新。这种现象在深层神经网络中尤为明显，因为梯度需要通过多层传递，每层的梯度都会进一步减小。对于Sigmoid和Tanh来说，于它们的导数在输入值较大或较小时接近于0，容易导致梯度消失问题，特别是在深层网络中。这使得网络难以训练，训练准确率较低。

​	ReLU在正区间内的导数为1，不会出现梯度消失问题，使得深层网络更容易训练。ReLU的计算非常简单，只需要判断输入是否大于0，计算效率高。ReLU在负区间内输出为0，使得部分神经元不会被激活，从而产生稀疏激活效果，减少计算量并提高模型的泛化能力。

​	不同激活函数的梯度分布不同，影响反向传播过程中梯度的传递。ReLU的梯度分布更有利于深层网络的训练，避免梯度消失问题，从而提高训练准确率。



#### ReLu死亡现象实验

![image-20250302141759856](C:\Users\sjq\Desktop\college\深度学习及其应用\lab1\image-20250302141759856.png)

思考题：

​	ReLu死亡现象成因：

​		ReLU激活函数在输入为负时输出为0，且导数为0。如果某个神经元的输入一直为负，其梯度在反向传播过程中将一直为0，导致权重无法更新。

​		如果学习率设置过高，权重更新幅度过大，可能导致神经元输出进入负区间，从而引发ReLU死亡现象。

​		如果权重初始化不当，可能导致某些神经元的初始输出为负，从而在训练初期就进入死亡状态。

​	解决方案：

​		动态调整学习率，如在训练初期使用较高的学习率，随着训练的进行逐渐降低学习率。避免神经元输出进入负区间，从而减少ReLU死亡现象的发生。

​		可以该井权重初始化，如采用Xavier或者He初始化，减少死亡现象。

​		LeakyReLU在负区间内引入一个小的斜率（如0.01），使得负输入时输出不为0，从而避免神经元死亡。PReLU在负区间内引入一个可学习的斜率参数，使得模型能够自适应地调整负区间的输出。ELU在负区间内引入一个指数函数，使得负输入时输出不为0，且具有平滑的过渡。使用ReLU变体可以有效缓解ReLU死亡现象，提高神经网络的训练效果和泛化能力。



#### 正则化方法实验

![image-20250302143119643](C:\Users\sjq\Desktop\college\深度学习及其应用\lab1\image-20250302143119643.png)

运行结果在.ipy2nb文件中有显示。

思考题：

​	在使用了L2正则化之后：

​		权重数值变小：L2正则化倾向于使权重值变小，因为较大的权重会增加正则化项的值，从而增加总损失。因此，优化过程中会倾向于选择较小的权重。

​		权重的分布更加集中：L2正则化使得权重分布更加集中，避免出现极端大的权重值，从而减少模型的复杂度。

​	其中，正则化系数 *λ* 控制正则化项的强度，影响模型参数的变化。较大的 λ* 会显著增加正则化项的影响，使得权重值更小，模型更加简单。然而，过大的 *λ* 可能导致模型欠拟合，无法捕捉数据中的复杂模式。较小的 *λ* 会减少正则化项的影响，允许权重值较大，模型更加复杂。然而，过小的 *λ* 可能导致模型过拟合，无法泛化到新数据。

​	较小的权重使得模型更加简单，减少了模型的复杂度，更倾向于捕捉数据中的主要模式，使得模型对输入数据的变化更加稳定，减少了对训练数据中噪声的敏感性，从而提高模型的泛化能力。较大的权重值可能导致模型对某些特征过度依赖，增加过拟合的风险。较小的权重值使得模型对所有特征更加均衡地依赖，减少过拟合的可能性。



#### Dropout

![image-20250302144026459](C:\Users\sjq\Desktop\college\深度学习及其应用\lab1\image-20250302144026459.png)

dropou层的实现如图所示。

思考题：

​	Dropout通过随机丢弃神经元，减少了神经元之间的复杂共适应关系。这意味着网络不能依赖于某些特定的神经元或特征组合，从而迫使网络学习更加鲁棒的特征。这有助于防止过拟合，因为模型不会过度依赖训练数据中的特定模式。所以，Dropout有效地起到了正则化的作用。

​	在训练时，Dropout随机丢弃神经元，增加了模型的多样性，提高了泛化能力。在测试时，所有神经元都参与预测，但为了保持输出的期望值一致，需要对权重进行比例缩放。这种差异处理确保了模型在训练和测试时的一致性，同时保留了Dropout的正则化效果。
